{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DksDuF7o_7-u"
      },
      "source": [
        "### introduction to Bioinformatics\n",
        "### homework 2\n",
        "### Name : Amirmohammad Ezzati\n",
        "### Student Id : 402212269"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DeZkoQ8K_7-w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import subprocess\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dwqUcwVx_7-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9b5a4a-f533-48fb-82e3-1c978f5b93f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded data for SRR390728_1.fastq.gz\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# FTP URL of the FASTQ file you want to download\n",
        "ftp_url = 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR390/SRR390728/SRR390728_1.fastq.gz'\n",
        "\n",
        "# Destination path where the downloaded file will be saved\n",
        "destination_path = 'SRR390728_1.fastq.gz'\n",
        "\n",
        "# Download data using wget\n",
        "try:\n",
        "    subprocess.run(['wget', ftp_url, '-O', destination_path], check=True)\n",
        "    print(f\"Downloaded data for SRR390728_1.fastq.gz\")\n",
        "except subprocess.CalledProcessError as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "n1vhBKhO_7-z"
      },
      "outputs": [],
      "source": [
        "#Now You have to read from SRR390728_1.fastq.gz file and save all of this file sequence in concatenated_sequence\n",
        "#hint : use gzip library and read about fastq files and how they save genomes sequence\n",
        "\n",
        "\n",
        "import gzip\n",
        "\n",
        "file_ = gzip.open('SRR390728_1.fastq.gz', 'rt')\n",
        "fastq = file_.read()\n",
        "\n",
        "fastq_splitted = fastq.split('\\n') # split fastq text line by line\n",
        "first_idx = fastq_splitted.index('+') # each sequence appears just before '+' in above list\n",
        "\n",
        "# so with bottom formula we can find all index of sequences in fastq_splitted list\n",
        "indexOfSequences = [ 4*i + first_idx - 1 for i in range(1 + (len(fastq_splitted)-1 - first_idx+1)//4)] if first_idx != 0 else [ 4*i + first_idx - 1 for i in range(1 + (len(fastq_splitted)-1 - first_idx+1)//4)][1:]\n",
        "\n",
        "\n",
        "concatenated_sequences = ''.join([fastq_splitted[i] for i in indexOfSequences])\n",
        "concatenated_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(concatenated_sequences)"
      ],
      "metadata": {
        "id": "wzCxZaCpOXk2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "QxGAtW6M_7-0"
      },
      "outputs": [],
      "source": [
        "#because genome is too long we just get first 35000 of genomes sequence and work with this genome after it\n",
        "#so only run this cell\n",
        "refrence_genome = concatenated_sequences[0:35000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQy1jK4__7-0"
      },
      "source": [
        "### just run the cell to create short reads from genome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74fUY2lL_7-1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Minimum length of each short read\n",
        "min_read_length = 90\n",
        "\n",
        "# Function to generate random short reads\n",
        "def generate_random_short_reads(sequence, min_length):\n",
        "    short_reads = []\n",
        "    remaining_sequence = sequence\n",
        "\n",
        "    while len(remaining_sequence) >= min_length:\n",
        "        read_length = random.randint(min(min_length, len(remaining_sequence)), min(len(remaining_sequence), 700))\n",
        "        short_read = remaining_sequence[:read_length]\n",
        "        short_reads.append(short_read)\n",
        "        remaining_sequence = remaining_sequence[read_length:]\n",
        "\n",
        "    return short_reads\n",
        "\n",
        "def mutate(input):\n",
        "    valid_inputs = ['A', 'C', 'T', 'G']\n",
        "    num = random.randint(1, 1000)\n",
        "    valid_inputs = [element for element in valid_inputs if element not in [input]]\n",
        "\n",
        "    if num < 40 :\n",
        "        shuffled_indices = list(range(len(valid_inputs)))\n",
        "        random.shuffle(shuffled_indices)\n",
        "        return valid_inputs[shuffled_indices[0]]\n",
        "    return input\n",
        "\n",
        "\n",
        "# Generate random short reads\n",
        "copy_num = 4\n",
        "short_reads = generate_random_short_reads(refrence_genome, min_read_length)\n",
        "\n",
        "for i in range (copy_num):\n",
        "    short_reads = short_reads + generate_random_short_reads(refrence_genome, min_read_length)\n",
        "\n",
        "\n",
        "shuffled_indices = list(range(len(short_reads)))\n",
        "random.shuffle(shuffled_indices)\n",
        "\n",
        "# Create a new list to store shuffled short reads\n",
        "short_reads = [short_reads[i] for i in shuffled_indices]\n",
        "\n",
        "#mutations\n",
        "for i in range (len(short_reads)):\n",
        "    for j in range (len(short_reads[i])):\n",
        "        mutate_char = mutate(short_reads[i][j])\n",
        "        if mutate_char != short_reads[i][j]:\n",
        "            if j != len(short_reads[i])-1:\n",
        "                short_reads[i] = short_reads[i][:j]+mutate_char+short_reads[i][j+1:]\n",
        "            else :\n",
        "                short_reads[i] = short_reads[i][:j]+mutate_char\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRgGQ4uj_7-2"
      },
      "source": [
        "### just run the code below (it's just for calculating local alignment score with refrence genome)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLUHWv7K_7-3"
      },
      "outputs": [],
      "source": [
        "\n",
        "def smith_waterman(sequence1, sequence2, match=2, mismatch=-1, gap_open=-2, gap_extend=-1):\n",
        "    len_seq1, len_seq2 = len(sequence1), len(sequence2)\n",
        "    score_matrix = np.zeros((len_seq1 + 1, len_seq2 + 1), dtype=int)\n",
        "\n",
        "    for i in range(1, len_seq1 + 1):\n",
        "        for j in range(1, len_seq2 + 1):\n",
        "            match_mismatch_score = match if sequence1[i - 1] == sequence2[j - 1] else mismatch\n",
        "            diagonal_score = score_matrix[i - 1][j - 1] + match_mismatch_score\n",
        "            gap_up_score = score_matrix[i - 1][j] + gap_extend if score_matrix[i - 1][j] > 0 else gap_open\n",
        "            gap_left_score = score_matrix[i][j - 1] + gap_extend if score_matrix[i][j - 1] > 0 else gap_open\n",
        "\n",
        "            score_matrix[i][j] = max(0, diagonal_score, gap_up_score, gap_left_score)\n",
        "\n",
        "    # Find the maximum score in the score matrix\n",
        "    max_score = np.max(score_matrix)\n",
        "\n",
        "    return max_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oqaB4R-R_7-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf9e6bac-055d-4ff4-fec3-463d5e0e7fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AGTGCTGATGTGGGAGCTGTGCGTGCTGGCCGCGCCAGGGCATCAGTGCTGATGTGGGGCCACTTGAAACTGGAGTGAGAAGCTGGTTACTTTCTATTACATAATAGCCACTTGAGACTAGAGTGAGAAGGTGAGTAGCTGGTTACTTGCTTGCAGTGCATCAGAAGGCCCAGTGGCCTTGGCAGGGGCAGGGGTGGCCTCCAGGGCCAGTGGCCTTGGCAGAGGCAGGCGGGGCCTCGTGAATGAGGGCCAGTGGCCTTGGCAGAGGCAGGTGTTCCTTGCAGTGCATCAGAACCAAGGTTTCTGGGGTCCCCGCAGACGAAGTAGGGCCAGTGGCCTTGGCAGAATCTCTAGAACGTCCCCGCAG\n",
            "TGTCGCTACAGAGTTACTCAGTTACTGCGTGGATCTCCTGTCGCAACTGTACAAGCGATGCACACTCCAAGTGCACGTTTGCCCGGCCCTGGGTACGCGTGAGTGGGTCAGAGTTACTGGAGCCCGGCCCTGGGTTGGCGTGAGTGGGTCAGGCTTAGAGTCCATGGAGCCCGGCCCTGGGTTGGCGTCACGTATTTAATACAGTATTGACTATTTGGATTTGCGCACATATTTAATACAGTATTGACTATTTGCATTTATCAACATTCTGAAAAAAGATCAACTGTTGAAGATCTAAAAAGATCAACCGTTGAACATCTTTAAGGTAAATTAAGATCAACTGTTGAAGATCTTTAAGGTATATTGCCATATTAGAAAAAC\n",
            "GAGACACAGTCTCCAACGCCACCAAAGCCTCCGTCGCAGCTCGTACGTTGCTGATACAGCACAAGATGCCGGCCCAGACACAGTCTCCACCGCCACCAAAGCCGCTGCCAGCCAGACACAGTCTCCAACGCAACCAAAGCCTCCGAAATCATCCAGATTTTTCAC\n",
            "TGTGATCCTGCAAAGCTCTAAGATACACATGGCCACTTTTGACATCACCCACATATGGGACTGGAGTTGGAAGGCCGGGCCTAACCACGCCCATGGGACCTGAGCAGTACTACCGAGCATA\n",
            "GCAGCTTCTCGTTTCCACACCTGTATATCTGTAGAAACAAGCACCTCATTCAACCCTGACAGCGCAGATCTGTAAAACTGAAATCTAAAGGATGCTTTCAACCATATAGAGCAGAGCTGTAAAACTGAAATCTGTAGTAACACAACAATTGTCTGAAAGTGAGACACTCTTGTGACTCACATTAAAAACTATGCTGTAGTAACAGTCAAATTTTTTACACAGGTTGTGGAGTGAGTGTCCCACTTCTTATTATACTCAGTTTGCTTTCCTGGAAGTGAAGGGGGCTCGAATGCTCTGAAAATAAACTTAACGGGCTTTGACAACAAATTCTAATCAGATTCTTTGACTTAATCAGATTCTTTGACTTCCAAGAAAGCAAACTCATTTTATTCTTTAGTTAATATAAATTCATTTCTAAACTAGGTGGATCCCATGAGGTCTTTGCTTCCTGGTCAGATTTTCATCCTTTGACCTGC\n",
            "AGGGCCGGGCTCCATGGACGCTAAGACTATATCCTGCTTAATGTAACCATACACTTTATAAATAAGAATATTTGCTGTTAAATGTAACCATACACTAAAATAAGAATATTTCCTCCTAAATGTAACCATACCCCA\n",
            "TAACCATGATACCCAGAAGTTCAAGGCTGTAGTGAGCCATGATCATCAGATCAGCACTGCAGTCTCATCTCATTGGAGGGTTAGCCTGGTCCACGGAGTGAGACCCTGTCTTAAAAACGGCCAGGCGCCCTCCAGCTGGGTGTGCACCAGGCACCTGGCCTGGCGCCCTCCAGCTGGGTGTGCACCAGGCACAAACCAACAAACATACAAACAAAAACCTACTACACAAACAAACAAACAAACAAACAAAAACCTACTACACCTAGTACAGGATCCATGCCAAAAAAATGTTAAACAATATTGATGCCTAAAAAATGTTAAACAAAACCAAAAAATCCCATGTGCCTGCAGTCTCCTCTTTGCAGCACCCAAGCACTGCTAAAACCCGTCCTGGCTAGTCTCAACCGAGATGAGTCTGCAATGCTGATCTTCCTGGTTACCCCTAGTCTCAACCCTTCAATGATATGAGACTGCAATGCTGATCTGCCTGGTTACCCGCTCCAGGCTCCAGCTTCTGGTTAACCGCTCCAGGATCGACCTTCAGTGACTGCAGTGTTTCTACAAATAATGATCTAAAACAACTACAGGTCCTAATAACAAGCTAGATA\n",
            "AGTTTTTGGGGTGGCCGAAGGTAAAGGATCTGGAGGGGACATCTCATGCCTCAGACAAGAAGAACAGGCAGAGCCCTTCTTGAGAAAGGAAGTTCTCAAATGCATCTCCCCGTCGGTCTAAAATTAGGGTGATACCATCCGGGAGGCCTGATAGTTGGTGCCCTGCCCATCAACAAGTCGGCATAGGAGATGAGCAGACACTCTGGGCCGGCCCAGCTTGCTTGCTCTAGGGGTCCAAGGCTTGTGCGAGGGGCCGTGGAGACTGCAGAACACAAATGGATAACGACAATTTTGGTTGGAATAGTCAAGATAGTAACAAAAATAAAAGC\n",
            "GCACATTTGTGTTGCACCGCAAAGTCTAGGTATAGCCACAGGGGAGCAGGAGGGCTCCATGGGGGAGGGGGCCCCCTGGGAACAGGTGGGAAGGTGCTGTTGAGATGGAAGAGTCGCTTACACATTCTGGACATTAGCCCCCGTCTTTCTTGTGCATGTGCACATTCATATTCTCTCACAAGAAAGAAATAAGATCAG\n",
            "AAGACTGCTGCTGGCTAGGCAGGCAGAAGACTGCTGGGGGCTATGTAGTAAGTTTATTCCGGTCCGCCAGTGAGTCCTTGGTTTTTAATAATGAAGAAGACTGCTGCTGGCTAGGCAGGAACTTCAATGTAGGGCGCCATCAGCCATTCCCAAAACACAAGGCCTGCAGGGCGCCATCAGCCATTCCCAAAACA\n"
          ]
        }
      ],
      "source": [
        "# Print 10 samples of short reads with length\n",
        "#TODO\n",
        "\n",
        "for i in range(10):\n",
        "  print(short_reads[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(short_reads))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2u8ciswfb8-6",
        "outputId": "72140614-0f21-44bf-81e3-55d5d34e6329"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "sNcGLLhl_7-5"
      },
      "outputs": [],
      "source": [
        "def find_high_overlap(seq1, seq2):\n",
        "  string1 = seq1\n",
        "  string2= (len(seq1)-1)* \" \" + seq2\n",
        "\n",
        "  highest_overlap=0\n",
        "\n",
        "  for k in range (len(seq1)):\n",
        "    overlap_num=0\n",
        "    #check individual characters to see if they match\n",
        "    for i in range(len(string1)):\n",
        "      overlap_num=0\n",
        "      if string1[i]==string2[i]:\n",
        "        for w in range(i, len(string1)):\n",
        "            if string1[w]==string2[w]:\n",
        "              overlap_num+=1\n",
        "            else:\n",
        "                overlap_num=0\n",
        "                break\n",
        "      # if the match is in the middle of the sequences\n",
        "      elif string1[i]!=\" \" and string2[i]!=\" \":\n",
        "          overlap_num=0\n",
        "          break\n",
        "      if overlap_num > highest_overlap:\n",
        "        highest_overlap = overlap_num\n",
        "    if overlap_num > highest_overlap:\n",
        "      highest_overlap = overlap_num\n",
        "    string2= string2[1:]+\" \"\n",
        "\n",
        "  return (highest_overlap)\n",
        "\n",
        "\n",
        "def merge(seq1, seq2, found_overlap):\n",
        "  string1 = seq1\n",
        "  string2= (len(seq1)-1)* \" \" + seq2\n",
        "\n",
        "  for k in range (len(seq1)):\n",
        "    overlap_num=0\n",
        "    #check individual characters to see if they match\n",
        "    for i in range(len(string1)):\n",
        "      overlap_num=0\n",
        "      if string1[i]==string2[i]:\n",
        "        for w in range(i, len(string1)):\n",
        "            if string1[w]==string2[w]:\n",
        "              overlap_num+=1\n",
        "            else:\n",
        "              overlap_num=0\n",
        "              break\n",
        "        if overlap_num == found_overlap:\n",
        "          #count the number of left spaces in the second sequence\n",
        "          spaces=0\n",
        "          for j in range(len(string2)):\n",
        "            if string2[j]==\" \":\n",
        "              spaces+=1\n",
        "            else:\n",
        "              break\n",
        "          merged_String= string1[:spaces]+string2[spaces:]\n",
        "\n",
        "          return merged_String.strip()\n",
        "    string2= string2[1:]+\" \"\n",
        "\n",
        "def no_merges(seq_matrix):\n",
        "  for row in range(len(seq_matrix)):\n",
        "    for col in range(len(seq_matrix)):\n",
        "      if seq_matrix[row][col]>0:\n",
        "        return False\n",
        "  return True\n",
        "\n",
        "\n",
        "# Function to perform greedy overlap-based assembly\n",
        "def heuristic_assemble(short_reads):\n",
        "  # keep looping until only one sequence is left\n",
        "  for seq in range(len(short_reads)-1):\n",
        "    seq_matrix = []\n",
        "    for item in short_reads:\n",
        "      seq_matrix.append(len(short_reads) * [0])\n",
        "\n",
        "    for row in range(len(seq_matrix)):\n",
        "      for col in range(len(seq_matrix)):\n",
        "        # the diagonal is how much it overlaps with itself\n",
        "        if row==col:\n",
        "          seq_matrix[row][col] = -1\n",
        "        else:\n",
        "          seq_matrix[row][col] = find_high_overlap(short_reads[row], short_reads[col])\n",
        "\n",
        "\n",
        "    if no_merges(seq_matrix)==True:\n",
        "      return short_reads\n",
        "\n",
        "    # find the highest overlap\n",
        "    highest = [0]\n",
        "    for i in range(len(seq_matrix)):\n",
        "      for j in range(len(seq_matrix)):\n",
        "        if seq_matrix[i][j]> highest[0]:\n",
        "          highest[0]=seq_matrix[i][j]\n",
        "          if len(highest)>1:\n",
        "            highest[1]=i\n",
        "            highest[2]=j\n",
        "          else:\n",
        "            highest.extend([i,j])\n",
        "\n",
        "    seq1=short_reads[highest[1]]\n",
        "    seq2=short_reads[highest[2]]\n",
        "\n",
        "    short_reads.append(merge(seq1,seq2, highest[0]))\n",
        "    short_reads.remove(seq1)\n",
        "    short_reads.remove(seq2)\n",
        "\n",
        "  return short_reads\n",
        "\n",
        "# Perform greedy overlap-based assembly\n",
        "assembled_sequence = heuristic_assemble(short_reads[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HINre-j3_7-5"
      },
      "source": [
        "### Your alignment score should be at least 1250"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(assembled_sequence[-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoIhdtnvcPLL",
        "outputId": "c2ec8f2d-fff5-439a-bbb4-7fd05fc3e7a7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5DIOCAYU_7-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26687f3a-18d2-43e3-e852-5012e0be0537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local Alignment Score: 3748\n"
          ]
        }
      ],
      "source": [
        "# Calculate the local alignment score using Smith-Waterman algorithm\n",
        "alignment_score = smith_waterman(refrence_genome, assembled_sequence[-1])\n",
        "\n",
        "# Print the local alignment score\n",
        "print(\"Local Alignment Score:\", alignment_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZ72NYpS_7-6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def perform_de_novo_assembly(short_reads, k):\n",
        "    kmers = {}\n",
        "\n",
        "    for read in short_reads:\n",
        "      # added kmer of each read to dictionary\n",
        "      for i in range(len(read) - k - 1):\n",
        "          kmers[read[i : i+k]] = read[i+1 : i+k+1]\n",
        "\n",
        "    kmer = list(kmers.keys())[0]\n",
        "    assembled_sequence = kmer[:-1]  # added first kmer to assembled sequence\n",
        "\n",
        "    while True:\n",
        "        if kmer in kmers:\n",
        "          # each step we add last character of kmer to assembled_sequence\n",
        "          assembled_sequence += kmer[-1]\n",
        "          kmer = kmers.pop(kmer)\n",
        "\n",
        "        # if exact kmer was not in kmers dictionary\n",
        "        else:\n",
        "          best_diff = k + 1 # bigger than kmer size\n",
        "          matched_kmer = ''\n",
        "          finished = True\n",
        "\n",
        "          # finding a kmer with least difference to match\n",
        "          for seq in list(kmers.keys()):\n",
        "            diff = 0\n",
        "            for i in range(len(seq)):\n",
        "              diff += 1 if kmer[i] != seq[i] else 0\n",
        "\n",
        "            if best_diff > diff:\n",
        "              best_diff = diff\n",
        "              matched_kmer = seq\n",
        "              # if we found a kmer with 5 differences at most we can continue to assembly\n",
        "              if diff <= 5:\n",
        "                finished = False\n",
        "              else:\n",
        "                finished = True\n",
        "\n",
        "          if finished:\n",
        "            return assembled_sequence\n",
        "          else:\n",
        "            finished = True\n",
        "            assembled_sequence += matched_kmer[-1]\n",
        "            kmer = kmers.pop(matched_kmer)\n",
        "\n",
        "\n",
        "de_brujin_assembled_sequence = perform_de_novo_assembly(short_reads, k=25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc2TrPnz_7-7"
      },
      "source": [
        "### Your alignment score should be at least 3800"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(de_brujin_assembled_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b9ih4Ndwidx",
        "outputId": "7ff879c8-a5a8-42a7-a6d6-89d9522217cc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5414"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-UxEGMjg_7-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd09552e-e14d-4901-b899-09a548a3619f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local Alignment Score: 8892\n"
          ]
        }
      ],
      "source": [
        "alignment_score = smith_waterman(refrence_genome, de_brujin_assembled_sequence)\n",
        "\n",
        "# Print the local alignment score\n",
        "print(\"Local Alignment Score:\", alignment_score)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}